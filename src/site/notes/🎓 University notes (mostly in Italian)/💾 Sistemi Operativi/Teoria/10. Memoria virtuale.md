---
{"dg-publish":true,"permalink":"/university-notes-mostly-in-italian/sistemi-operativi/teoria/10-memoria-virtuale/","created":"2023-06-24T14:49:24.445+02:00","updated":"2023-06-24T14:49:24.445+02:00"}
---

# 10. Memoria virtuale
Le tecniche viste in memoria prevedono che tutti i dati di un processo siano caricati in memoria al momento della sua esecuzione. Con l'evoluzione del software, caricare tutto in memoria, con software di grandi dimensioni, non sempre Ã¨ possibile, ma soprattutto non Ã¨ sempre necessario. Basti pensare che molti programmi moderni pesano molti piÃ¹ GB di quanto la RAM sia fisicamente in grado di contenere. E come se non bastasse, un programma pesa di piÃ¹ dentro la RAM perchÃ© diventando un processo verranno aggiunte informazioni aggiuntive, come la stack (vedi [[ðŸŽ“ University notes (mostly in Italian)/ðŸ’¾ Sistemi Operativi/Teoria/4. Gestione dei processi e threads#Da cosa Ã¨ formato un processo?\|4. Gestione dei processi e threads#Da cosa Ã¨ formato un processo?]]).
Per risolvere questo problema Ã¨ dunque stata introdotta la memoria virtuale, con cui Ã¨ possibile considerare parte del disco come memoria primaria (quindi _Memoria virtuale = RAM + parte di disco_) e caricare in memoria solo le parti del programma necessarie per l'esecuzione attuale. Sebbene generalmente complessa da implementare, la memoria virtuale permette di caricare piÃ¹ processi in memoria, aumentando quindi il throughput, ed inoltre permette facilmente la condivisione di risorse fra processi. Esistono varie tecniche per realizzare la memoria virtuale, ma si vedrÃ  che, come per la paginazione, la memoria virtuale sembri quasi una naturale evoluzione.

## Paginazione su richiesta (on demand)
Sostanzialmente mi permette di eseguire programmi piÃ¹ grandi della RAM caricando dentro quest'ultima **solo una parte delle pagine e solo quando necessario**. Le pagine restanti vengono caricate su disco (backing store) e prese tramite swapping. 
Per capire se una pagina Ã¨ dentro la ram o su disco utilizzo i bit di validitÃ  presenti nella page table:
- **bit a 1:** pagina in memoria
- **bit a 0:** pagina NON in memoria

Inizialmente i bit di validitÃ  sono tutti 0. Dunque, ad ogni istruzione, se la pagina richiesta Ã¨ presente in memoria si va avanti normalmente, altrimenti si verifica un cosiddetto **page fault**.

### Page fault
Un page fault causa un interrupt al SO che avviene in queste 5 fasi:
1. Il S.O. stabilisce la validitÃ  del riferimento del processo chiamante. Se non Ã¨ valido abortisce il page fault.
2. Cerca un frame vuoto nella RAM o dal quale rimuovere una pagina
3. Effettua lo swap dal disco della pagina richiesta
4. Modifica il bit di validitÃ  a 1 perchÃ© ora la pagina Ã¨ in memoria 
5. Ripristina l'istruzione che ha causato il page fault

Come detto sopra, il primo accesso in memoria di un programma risulta sempre in page fault (perchÃ© la tabella Ã¨ ancora vuota).

### Effective Access Time (EAT)
Ovviamente la paginazione su domanda influenza il tempo di accesso effettivo alla memoria (Effective Access Time, EAT), visto che la velocitÃ  dipende da quanti page fault avvengono, e quindi se trovo la pagina giÃ  in memoria o no. Possiamo allora calcolare il tempo di accesso effettivo alla pagina. Nella formula sottostante $p$ rappresenta il tasso di page fault, ovvero la probabilitÃ  che un page fault si verifichi. Ovviamente $0 \leq p \leq 1$, dove $p = 0$ significa nessun page fault, mentre $p = 1$ ogni accesso Ã¨ un page fault.
$$\text{EAT} = (1 - p) \cdot t_{mem} + p \cdot t_{page fault}$$
Dove $t_{page fault}$ Ã¨ dato da tre componenti: il servizio dellâ€™interrupt, lo swap in (lettura della pagina),
e costo di riavvio del processo (e lo swap out (opzionale)). Invece $t_{mem}$ rappresenta il tempo di accesso alla memoria.

#### Esempio
Dati:
- $t_{mem}= 100\ ns$
- $t_{page\ fault} = 1\ ms\ (10^6\ ns)$

Dunque
$$\text{EAT} = (1-p) \cdot 100 + p \cdot  10^6 = 100 â€“ 100 \cdot p + 10^6 \cdot p = 100 \cdot (1+9999 \cdot p)\ ns$$

Vediamo quanto deve valere $p$ per mantenere un peggioramento al massimo del 10% rispetto al tempo di accesso standard:

$$\overbrace{100 \cdot (1.1)}^{\text{Accesso standard alla memoria}} > 100 \cdot (1+9999\cdot p) \leftrightarrow p < 0.0001 â‰ˆ 10^{-4}$$

Dunque circa $1$ page fault ogni $10000$ accessi! Ne segue che Ã¨ fondamentale tenere basso il livello di page fault.

Vediamo ora cosa succede se non ci sono pagine libere da rimpiazzare.

### Rimpiazzamento delle pagine
Se non ci sono pagine libere si cercano pagine (frame) in memoria e si fa lo swap su disco di tali pagine. Per far questo Ã¨ necessario un algoritmo che massimizzi le prestazioni minimizzando il numero di page fault. 
Vediamo quindi il funzionamento del rimpiazzamento delle pagine.
In caso di assenza di frame liberi nel caso di un page fault il sistema operativo verifica su una tabella associata al processo se si tratta di page fault o violazione di accesso. Se Ã¨ una violazione di accesso fa un abort, altrimenti cerca un frame vuoto e se non câ€™Ã¨ usa un algoritmo di rimpiazzamento delle pagine per scegliere un frame vittima. 
Saranno necessari quindi 2 accessi alla memoria, uno per per fare lo swap out della vittima (nel disco) e uno per fare lo swap in del frame da caricare (in memoria).
Quindi una volta scelta la vittima, fa lo swap out di essa su disco, lo swap in della pagina nel frame da disco, modifica le tabelle e ripristina lâ€™istruzione che ha causato il page fault. Si noti come in assenza di frame liberi il tempo di page fault si raddoppia. Pertanto si ottimizza utilizzando un bit nella page table detto **bit di modifica** o dirty bit che vale 1 se la pagina Ã¨ stata modificata dal momento in cui viene ricaricata e solo le pagine che vengono modificate vengono scritte su disco quando diventano vittime.

### Problematiche
Dunque le problematiche della paginazione su domanda sono la scelta della pagina da rimpiazzare e lâ€™allocazione del numero di frame ad un processo al momento dellâ€™esecuzione. Vediamo ora come risolvere questi 2 problemi.

### Algoritmi di rimpiazzamento delle pagine
Il tasso di page fault, che deve essere tenuto basso per non compromettere le prestazioni, dipende molto da come viene scelta la pagina da rimpiazzare. Dunque lâ€™obiettivo di questi algoritmi Ã¨ di minimizzare il numero di page fault. Si valuta lâ€™esecuzione di una particolare stringa di riferimenti a memoria detta _reference string_ e si calcolano il numero di page fault sulla stringa. Ãˆ sempre necessario sapere il numero di frame disponibili per il processo. Il tasso di page fault Ã¨ inversamente proporzionale al numero di frame (piÃ¹ frame $\rightarrow$ piÃ¹ spazio per tutti).

#### Algoritmo FIFO (first-in-first-out)
In questo algoritmo la prima pagina introdotta Ã¨ la prima ad essere rimossa. Lâ€™algoritmo Ã¨ cieco in
quanto non viene valutata lâ€™importanza (frequenza di riferimento) della pagina rimossa. Tende ad
aumentare il tasso di page fault e soffre dellâ€™anomalia di Belady.

##### anomalia di Belady
Nellâ€™anomalia di Belady il numero di page fault non puÃ² decrescere allâ€™aumentare del numero di frame usando FIFO, mentre a volte piÃ¹ frames equivalgono a piÃ¹ page fault.

##### Esempio 1
In questo esempio abbiamo 3 frame e con una _reference string_ lunga solamente 20 abbiamo 15 page fault!

![ADR-FIFO1.png|700](/img/user/%F0%9F%8E%93%20University%20notes%20(mostly%20in%20Italian)/%F0%9F%92%BE%20Sistemi%20Operativi/Teoria/_images/ADR-FIFO1.png)

##### Esempio 2
In questo esempio abbiamo 3 frame e con una _reference string_ lunga solamente 12 abbiamo 9 page fault!

![ADR-FIFO2.png|700](/img/user/%F0%9F%8E%93%20University%20notes%20(mostly%20in%20Italian)/%F0%9F%92%BE%20Sistemi%20Operativi/Teoria/_images/ADR-FIFO2.png)

#### Algoritmo ideale
Come sarebbe fatto quindi un algoritmo ideale?
Garantisce il minimo numero di page fault rimpiazzando le pagine che non saranno usate per il periodo di tempo piÃ¹ lungo. Questa informazione richiede una conoscenza anticipata della stringa dei riferimenti e ci si ritrova in una situazione simile a SJF e pertanto lâ€™implementazione Ã¨ impossibile a meno di approssimazioni. Rimane comunque un utile riferimento per altri algoritmi.

##### Esempio
In questo esempio abbiamo 3 frame e con una _reference string_ lunga solamente 20 avremmo solamente 9 page fault. Viene rimpiazzata la pagina che sarÃ  riusata in seguito alle altre 2 pagine nei frame.

![ADR-Ideale.png|700](/img/user/%F0%9F%8E%93%20University%20notes%20(mostly%20in%20Italian)/%F0%9F%92%BE%20Sistemi%20Operativi/Teoria/_images/ADR-Ideale.png)

#### Algoritmo least recently used (LRU)
Questo algoritmo Ã¨ unâ€™approssimazione dellâ€™algoritmo ottimo e usa il passato recente come previsione del futuro rimpiazzando la pagina che non viene usata da piÃ¹ tempo. Ãˆ di difficile implementazione in quanto non Ã¨ banale ricavare il tempo dellâ€™ultimo utilizzo e puÃ² richiedere notevole hardware addizionale. 

##### Esempio
In questo esempio abbiamo 4 frame e con una _reference string_ lunga solamente 12 abbiamo 8 page fault.
Dunque Ã¨ decisamente migliore del FIFO ma peggiore dell'algoritmo ideale (ovviamente).
![ADR-LRU.png|700](/img/user/%F0%9F%8E%93%20University%20notes%20(mostly%20in%20Italian)/%F0%9F%92%BE%20Sistemi%20Operativi/Teoria/_images/ADR-LRU.png)

##### Implementazioni
Vediamo ora delle possibili implementazioni di questo algoritmo.

###### Tramite contatore
Ad ogni pagina Ã¨ associato un contatore e ogni volta che la pagina viene referenziata il clock di sistema Ã¨ copiato nel contatore. Si rimpiazza la pagina con il valore piÃ¹ piccolo del contatore. Si noti come tale pagina vada cercata.

###### Tramite stack
Viene mantenuto uno stack di numeri di pagina e quando si fa riferimento ad una pagina questa viene estratta dalla sua posizione e messa in cima. Lâ€™aggiornamento richiede lâ€™estrazione di un elemento interno allo stack. Al fondo dello stack si trova la pagina LRT. Si noti come in questo caso non Ã¨ necessaria alcuna ricerca, in quanto la pagina designata Ã¨ sempre in fondo, ma aggiornare il riferimento, rimuovendo un elemento dal centro, richiede una ricerca $\mathcal O(n)$.

![ADR-LRU-Stack.png|400](/img/user/%F0%9F%8E%93%20University%20notes%20(mostly%20in%20Italian)/%F0%9F%92%BE%20Sistemi%20Operativi/Teoria/_images/ADR-LRU-Stack.png)


###### Uso del bit di reference
Che viene associato ad ogni pagina inizialmente a 0. Quando la pagina Ã¨ referenziata, il bit di reference viene impostato a 1 dallâ€™hardware. Per il rimpiazzamento si sceglie una pagina che ha il bit a 0. Si noti come Ã¨ approssimato in quanto non viene verificato lâ€™ordine di riferimento delle pagine.

In alternativa, si usano piÃ¹ bit di reference (registro di scorrimento) per ogni pagina. I bit vengono aggiornati periodicamente e si usano i bit come valori interi per scegliere la LRU, ovvero quella con il valore piÃ¹ basso di registro di scorrimento.

##### Approssimazioni
Le tecniche viste sopra implementano deterministicamente il LRU, ma sono costose in termini di HW. Esistono implementazioni alternative meno costose, che sono tuttavia a loro volta delle approssimazioni.

###### Algoritmo LFU (Least Frequently Used)
Mantiene un conteggio del numero di riferimenti fatti ad ogni pagina e rimpiazza quella con il conteggio piÃ¹ basso. PuÃ² non corrispondere al â€œLRUâ€, visto che, se per esempio ho molti riferimenti iniziali, una pagina puÃ² avere conteggio alto e non essere eseguita da molto tempo.

###### Algoritmo MFU (Most Frequently Used)
Ãˆ l'opposto di LFU, la pagina con il conteggio piÃ¹ basso Ã¨ probabilmente stata appena caricata e dovrÃ  essere presumibilmente usata ancora (localitÃ  dei riferimenti).

###### Algoritmo second chance (clock)
Si basa su una FIFO circolare basata su bit di reference: se il bit Ã¨ a 0 si rimpiazza, se a 1 si mette a 0 e si analizza la pagina successiva.
Variante: Si usano piÃ¹ bit di reference.

### Allocazione dei frame
Data una memoria con $N$ frame e $M$ processi Ã¨ importante scegliere quanti frame allocare ad ogni processo non violando il fatto che ogni processo necessita di un minimo numero di pagine per poter essere eseguito in quanto lâ€™istruzione interrotta da un page fault deve esser fatta ripartire. Pertanto il numero di pagine deve essere uguale al massimo numero di indirizzi specificabile in unâ€™istruzione. I valori tipici vanno da 2 a 4 frame. Inoltre lo schema di allocazione puÃ² essere fisso, in cui un processo ha sempre lo stesso numero di frame, o variabile, in cui il numero di frame allocati puÃ² variare durante lâ€™esecuzione. Se il numero di pagine Ã¨ minore al massimo numero di indirizzi specificabile in unâ€™istruzione, si potrebbe verificare una situazione di costante page fault per il processo. Una volta specificato questo vincolo, Ã¨ possibile classificare gli algoritmi in due famiglie, a seconda della politica di allocazione dei frame: rimpiazzamento locale o globale. Nel primo caso i frame vittima possono essere scelti solo tra i frame allocati dal processo stesso (sceglie la vittima tra i frame che ha); in questo modo il numero di frame per processo rimane fisso. Se si parla di rimpiazzamento globale, la vittima puÃ² essere scelta tra tutti i frame in memoria, quindi anche degli altri processi. In questo modo Ã¨ piÃ¹ difficile tracciare il tasso di page fault, ma in generale questo metodo dinamico aumenta il throughput ed Ã¨ per questo preferito. Vediamo un po' piÃ¹ in dettaglio la differenza tra allocazione fissa e variabile.

#### Allocazione fissa
##### Allocazione in parti uguali
Dati $m$ frame e $n$ processi si alloca ad ogni processo $\frac m n$ frame.
##### Allocazione proporzionale
Alloca secondo la dimensione del processo, parametro non sempre significativo in quanto la prioritÃ  puÃ² essere piÃ¹ significativa.

#### Allocazione variabile
Permette di modificare dinamicamente le allocazioni ai vari processi. Dobbiamo perÃ² capire in che modo effettuare le allocazioni. Esse avvengono in base al calcolo del _working set_ o della _page fault frequency (PFF)_.

##### Calcolo del working set
Si definisce working set la quantitÃ  di memoria che un processo richiede per svolgere le proprie funzioni in un dato istante $t$. Il working set dipende dalla localitÃ  del programma (un processo passa da una localitÃ  di indirizzi allâ€™altra durante la sua esecuzione come array, procedure e moduli) ed Ã¨ per questo definito in funzione del tempo.
Quindi un criterio per rimodulare lâ€™allocazione dei frame consiste nel calcolare quali sono le richieste effettive di ogni processo in base al modello della localitÃ . Idealmente un processo necessita di un numero di frame pari alla sua localitÃ . Ma come la misuro? Effettuando una stima!

###### Modello del working set
Per la stima del working set, un metodo semplice quanto veloce consiste nel considerare un dato intervallo di riferimenti $\Delta$: tutte le pagine che compaiono nell'intervallo (chiamato _finestra del working set_) fanno parte del working set ed il numero ne costituisce la cardinalitÃ  (dimensione). Ovviamente si deve prestare attenzione alla dimensione di $\Delta$. Se Ã¨ troppo piccolo Ã¨ poco significativo, se Ã¨ troppo grande copre varie localitÃ  e se vale infinito comprende tutto il programma. Vediamo ora come calcolare approssimativamente il working set.
Il working set viene calcolato approssimando tramite **timer e bit di reference**: si usa un timer che interrompe periodicamente la CPU; allâ€™inizio di ogni periodo i bit di reference vengono posti a 0 e ad ogni interruzione del timer le pagine vengono scansionate; quelle con bit di reference a 1 si trovano nel working set, quelle con valore 0 vengono scartate.
Lâ€™accuratezza aumenta in base al numero di bit e alla frequenza di interruzioni. La richiesta totale di frame Ã¨ $D = \sum_i WSS_i$, dove $WSS_i$ Ã¨ la dimensione del $WS_i$. Se $D$ Ã¨ maggiore del numero totale di frame si verifica un fenomeno chiamato **thrashing** in cui un processo spende tempo di CPU continuando a swappare pagine da e verso la memoria. Di conseguenza i nuovi processi "rubano" frame ai vecchi processi aumentando il numero di page fault, portando ad un declino costante dell'utilizzo della CPU. Si deve pertanto stimare con esattezza il numero di frame necessari a un processo per non entrare in thrashing.

##### Frequenza dei page fault
Una soluzione alternativa e piÃ¹ accurata del working set Ã¨ la frequenza dei page fault: si stabilisce un tasso di page fault accettabile. Se quello effettivo Ã¨ troppo basso il processo rilascia dei frame, se Ã¨ troppo alto ne ottiene altri.

## Conclusioni
La selezione della dimensione della pagina deve essere fatta accuratamente in quanto si deve sempre
fare un trade-off:

Pagine piccole:
- Frammentazione.
- Molte entry nella page table.
- Costo di lettura e scrittura non ammortizzato.
- LocalitÃ .

Pagine grandi:
- Frammentazione interna significativa.
- Grande dimensione della page table.
- I/O overhead.
- Grande granularitÃ , si deve anche trasferire ciÃ² che non Ã¨ necessario.

Naturalmente la struttura dei programmi influisce sul numero di page fault e in alcuni casi esistono frame che non devono essere mai rimpiazzati come frame corrispondenti a pagine del kernel e altri corrispondenti a pagine usate per trasferire dati da e verso I/O. Questi subiscono il blocco di frame (frame locking).