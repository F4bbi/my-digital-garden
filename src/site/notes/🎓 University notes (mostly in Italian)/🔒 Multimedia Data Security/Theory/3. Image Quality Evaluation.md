---
{"dg-publish":true,"permalink":"/university-notes-mostly-in-italian/multimedia-data-security/theory/3-image-quality-evaluation/","created":"2025-02-05T07:33:48.274+01:00","updated":"2025-02-23T23:22:35.882+01:00"}
---

# 3. Image Quality Evaluation
Image Quality Evaluation is a key component in assessing the quality of a processed multimedia signal, such as images subjected to coding, transmission, watermarking, or other forms of manipulation. The evaluation methods can generally be categorized into two main types: **objective (computed) measures** and **subjective measures**.

- **Objective measures** are computationally efficient but can sometimes be unreliable as they do not always align with human perception.
    
- **Subjective measures** are based on human judgment and provide a more accurate reflection of visual quality but are complex, expensive, and non-repeatable.

## Quality Assessment
Let's see them in details.

### Subjective Assessment

Subjective quality assessment relies on the [[ðŸŽ“ University notes (mostly in Italian)/ðŸ”’ Multimedia Data Security/Theory/4. HVS & Watermarking\|Human Visual System]] who rate the quality of an image according to a predefined scale. Typically, observers are asked to compare the processed image with the original and provide a quality score.

A standard subjective rating scale is as follows:

| Rating                        | Description |
| ----------------------------- | ----------- |
| **Imperceptible**             | Excellent   | 
| **Perceptible, not annoying** | Good        |
| **Slightly annoying**         | Fair        |
| **Annoying**                  | Poor        |
| **Very annoying**             | Bad         |

#### Disadvantages of Subjective Measures

- **Expensive**: Conducting tests requires multiple human evaluators and resources.
    
- **Non-repeatable**: Different observers may provide varying assessments based on personal perception.
    
- **Limited sensitivity**: Small differences between the original and altered images might not always be distinguishable.

Due to the limitations of subjective measures, **objective measures** are necessary to provide automated and repeatable evaluations.

## Objective Measures

Objective measures evaluate image quality mathematically, comparing a processed image to its original counterpart. Some common objective measures are the following:

### Mean Absolute Difference (MAD)
The formula is the following:

$$\text{MAD} = \frac{1}{N} \sum_{k} \sum_{m,n} \left| V_1(m,n,k) - V_2(m,n,k) \right|$$

### Mean Square Error (MSE)
The formula is the following:

$$\text{MSE} = \frac{1}{N} \sum_{k} \sum_{m,n} \left( V(m,n,k) - V_2(m,n,k) \right)^2$$

### Peak Signal-to-Noise Ratio (PSNR)
The formula is the following:

$$\text{PSNR} = 10 \log_{10} \left( \frac{V_{\text{max}}^2}{\text{MSE}} \right)$$

WhereÂ $V_{\text{max}}$â€‹Â is the maximum pixel value (e.g., 255 for 8-bit images). Higher PSNR indicates better quality, but it assumes uniform perceptual importance of errors.

### Limitations of Traditional Objective Metrics

While these measures are widely used, they have certain limitations:

- **All artifacts are weighted equally**, without considering their perceptual impact.
- **Pixel-wise comparison** does not account for spatial dependencies or structural distortions.
- **No context-awareness**: A small shift in an image may drastically change the metric score even if perceptual quality remains similar.
- **Ignoring Human Visual System (HVS)**: Traditional metrics do not consider how humans perceive visual distortions.

For example, two images with the same MSE might have significantly different perceptual qualities, demonstrating the limitations of these metrics. You can see an example below.

![Pasted image 20250205080727.png|700](/img/user/%F0%9F%8E%93%20University%20notes%20(mostly%20in%20Italian)/%F0%9F%94%92%20Multimedia%20Data%20Security/_images/Pasted%20image%2020250205080727.png)

## Improved Methods: Weighted PSNR (WPSNR)

To address these issues, **Weighted PSNR (WPSNR)** incorporates a model based on the Human Visual System.

### Key Concept

- The human eye is **less sensitive to changes in textured areas** than in smooth areas.
- WPSNR introduces a weighting function called the **Noise Visibility Function (NVF)**, which considers texture masking effects.

### WPSNR Formula

$$WPSNR= 10 \cdot \log_{10} \left(\frac{255^2}{MSE \cdot NVF^2}\right)$$

> [!info] 
> If $NVF<1$, $WPSNR$ will be slightly higher than $PSNR$

### Noise Visibility Function (NVF)

The NVF is modeled using a Gaussian function to estimate texture strength:

$$NVF = \text{NORM}\left\{\frac{1}{1 + \sigma^2_{block}}\right\} \in [0,1]$$

where $NORM$ is the normalization function and $\sigma^2_{block}$ represents the local luminance variance in a block of pixels.

This is the idea:

- **Flat regions** (smooth areas): NVF â†’ 1 (higher sensitivity to distortion)
- **Edges and textures**: NVF â†’ 0 (lower sensitivity to distortion)

### Benefits of WPSNR

- **More accurate perceptual quality assessment** compared to traditional PSNR.
- **Enables stronger watermarking in textured images** without noticeable degradation.
- **Accounts for Human Visual System properties**, improving reliability.

For example, a highly textured image like **Baboon** has a **higher perceptual capacity**, allowing for stronger watermark embedding with minimal perceptual loss.